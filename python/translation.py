# -*- coding: utf-8 -*-
"""Translation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z_E6pqAGiAgQj_SoQd3pZol9GB4iOvqi
"""

from google.colab import drive  # to mount Drive to Colab notebook
# Connect Google Drive to Colab
drive.mount('/content/gdrive')
# Create a local variable to store the data path on your drive  
path = "/content/gdrive/MyDrive/CP_Project"

path = "/content/gdrive/MyDrive/MA_ECON/Semester-2/Computer Programming /final_tweets.csv"

import pandas as pd
df_tweet = pd.read_csv(path)
df_tweet.head()

"""#Google Translation API """

!pip install googletrans
import googletrans                     #import the installed Google Translate API module 
from googletrans import Translator     #import the Translator class from googletrans module
translator = Translator()              #initalize the Translator class object

"""#Easynmt """

!pip install -U easynmt
!pip install langdetect
!pip install langid
!pip install fasttext

#import EasyNMT from easynmt module 
from easynmt import EasyNMT
model = EasyNMT('opus-mt')

"""###Clean the dataset and detect the script langauge """

#remove the emojis from the dataset 
!pip install validators

#create another column final text by removing urls from the text 
df = df_tweet.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))
df['final_text'] = df['full_text'].replace(r'http\S+', '', regex=True).replace(r'www\S+', '', regex=True)

#to test if the above code worked or not 
import validators

def isUrlValid(url):
    return True if validators.url(url) else False
df['isURLValid'] = df['final_text'].apply(isUrlValid) 
df.head(10)

#to check if a value is "True" in isURLValid 
df.loc[(df['final_text'] == 'TRUE')]

"""#detection of language and filter in a new row """

!pip install goslate

#import the module goslate to translate the data 
import goslate

gs = goslate.Goslate()



from langdetect import detect
def detect_lang(text):
    return detect(text)

#to detect first 30 characters in the columns 
textlang = [detect(elem) for elem in df_tweet['full_text'] if len(elem) > 30]
textlang = [detect(elem) if len(elem) > 30 else elem == 'no' for elem in df_tweet['full_text']
textlang

texl70 = df_tweet['full_text']
langdet = []                                                    
for i in range(len(df_tweet)):                                         
    try:                                                          
       lang=detect(texl70[i])                                      
    except:                                                       
       lang='no'                                                  
       print("This row throws error:", texl70[i])                 
    langdet.append(lang)

"""##Trying another lang detector  """

$ pip install polyglot
from polyglot.detect import Detector